\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }

\title{Neural Machine Translation and Attention Module Suggested Readings}
\author{XCS224N Natural Language Processing with Deep Learning}
\date{}

\begin{document}

\maketitle

\section{Suggested Readings}
\begin{enumerate}
    \item \href{https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/syllabus.shtml}{Statistical Machine Translation slides, CS224n 2015 (lectures 2/3/4)}
    \item \href{https://www.aclweb.org/anthology/P02-1040.pdf}{BLEU (original paper)}
    \item \href{https://arxiv.org/pdf/1409.3215.pdf}{Sequence to Sequence Learning with Neural Networks (original seq2seq NMT paper)}
    \item \href{https://arxiv.org/pdf/1211.3711.pdf}{Sequence Transduction with Recurrent Neural Networks (early seq2seq speech recognition paper)}
    \item \href{https://arxiv.org/pdf/1409.0473.pdf}{Neural Machine Translation by Jointly Learning to Align and Translate (original seq2seq+attention paper)}
    \item \href{https://distill.pub/2016/augmented-rnns/}{Attention and Augmented Recurrent Neural Networks (blog post overview)}
    \item \href{https://arxiv.org/pdf/1703.03906.pdf}{Massive Exploration of Neural Machine Translation Architectures (practical advice for hyperparameter choices)}
    \item \href{https://arxiv.org/pdf/1604.00788.pdf}{Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models}
    \item \href{https://arxiv.org/pdf/1808.09943.pdf}{Revisiting Character-Based Neural Machine Translation with Capacity and Compression}
\end{enumerate}

\end{document}

