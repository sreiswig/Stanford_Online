\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }

\title{RNNs and Language Models Module Suggested Readings}
\author{XCS224N Natural Language Processing with Deep Learning}
\date{}

\begin{document}

\maketitle

\section{Suggested Readings}
\begin{enumerate}
    \item \href{https://web.stanford.edu/~jurafsky/slp3/3.pdf}{N-gram Language Models}
    \item \href{http://karpathy.github.io/2015/05/21/rnn-effectiveness/}{The Unreasonable Effectiveness of Recurrent Neural Networks (blog post overview)}
    \item \href{https://www.deeplearningbook.org/contents/rnn.html}{Sequence Modeling: Recurrent and Recursive Neural Nets (Sections 10.1 and 10.2)}
    \item \href{http://norvig.com/chomsky.html}{On Chomsky and the Two Cultures of Statistical Learning}
    \item \href{https://www.deeplearningbook.org/contents/rnn.html}{Sequence Modeling: Recurrent and Recursive Neural Nets (Sections 10.3, 10.5, 10.7-10.12)}
    \item \href{https://arxiv.org/pdf/1211.5063.pdf}{On the difficulty of training Recurrent Neural Networks (proof of vanishing gradient problem)}
    \item \href{https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/lectures/vanishing_grad_example.html}{Vanishing Gradients Jupyter Notebook (demo for feedforward networks)}
    \item \href{http://colah.github.io/posts/2015-08-Understanding-LSTMs/}{Understanding LSTM Networks (blog post overview)}
\end{enumerate}

\end{document}

